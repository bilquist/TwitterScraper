{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Import the necessary methods from tweepy library\n",
      "from tweepy.streaming import StreamListener\n",
      "from tweepy import OAuthHandler\n",
      "from tweepy import Stream\n",
      "from tweepy import API\n",
      "import json\n",
      "import pyodbc\n",
      "import re\n",
      "\n",
      "# Tell urllib3 to switch the ssl backen to PyOpenSSL with inject_into_urllib3():\n",
      "# This is not part of tweepy but exists to get rid of the InsecurePlatformWarning as suggested here:\n",
      "# https://urllib3.readthedocs.org/en/latest/security.html#insecureplatformwarning\n",
      "#import urllib3.contrib.pyopenssl\n",
      "#urllib3.contrib.pyopenssl.inject_into_urllib3()\n",
      "# Remove as it conflicts with another library\n",
      "\n",
      "# Variables that contain the user credentials to access Twitter API\n",
      "access_token = \"access token here\"\n",
      "access_token_secret = \"access token secret here\"\n",
      "consumer_key = \"consumer key here\"\n",
      "consumer_secret = \"consumer secret here\"\n",
      "\n",
      "\n",
      "class TweetParserDB():\n",
      "    \n",
      "    # Initiate variables\n",
      "    FILTER = [\"in a while crocodile\",\n",
      "              \"after a while crocodile\",\n",
      "              \"in awhile crocodile\",\n",
      "              \"after awhile crocodile\",\n",
      "              \"in a while, crocodile\",\n",
      "              \"after a while, crocodile\",\n",
      "              \"in awhile, crocodile\",\n",
      "              \"after awhile, crocodile\"\n",
      "             ]\n",
      "    regex = re.compile('|'.join(FILTER).lower())\n",
      "    search_string = None\n",
      "    \n",
      "    \n",
      "    def retrieve_tweet_json(self, fetched_screen_name):\n",
      "        allTweets = []\n",
      "        public_tweets = api.user_timeline(screen_name=fetched_screen_name, include_rts=True)\n",
      "        for tweet in public_tweets:\n",
      "            decoded = tweet._json\n",
      "            allTweets.append(tweet)\n",
      "        return allTweets\n",
      "        \n",
      "\n",
      "    def fetch_tweets(self, decoded, cursor):\n",
      "                    \n",
      "        # Create variables from Tweet text to make sure our phrases of interest are in it\n",
      "        enc = lambda x: x.encode('utf8', errors='ignore')\n",
      "        tweet_text = enc(decoded['text']) if \"text\" in decoded else \"\"\n",
      "        tweet_match = re.search(self.regex, tweet_text.lower())\n",
      "        are_coordinates_set = False\n",
      "        \n",
      "        # Only parse tweets that meet our filter condition\n",
      "        if tweet_match:\n",
      "        \n",
      "            tweet_insert_list = []\n",
      "            tweet_id = decoded['id'] if \"id\" in decoded else None\n",
      "            created_at = decoded['created_at'] if \"created_at\" in decoded else None\n",
      "            tweet_text = decoded['text'] if \"text\" in decoded else None\n",
      "            tweet_source = decoded['source'] if \"source\" in decoded else None\n",
      "            truncated = decoded['truncated'] if \"truncated\" in decoded else None\n",
      "            in_reply_to_status_id = decoded['in_reply_to_status_id'] if \"in_reply_to_status_id\" in decoded else None\n",
      "            in_reply_to_user_id = decoded['in_reply_to_user_id'] if \"in_reply_to_user_id\" in decoded else None\n",
      "            in_reply_to_user_screen_name = decoded['in_reply_to_user_screen_name'] if \"in_reply_to_user_screen_name\" in decoded else None\n",
      "            has_coordinates = decoded['coordinates'] if \"coordinates\" in decoded else None\n",
      "            if has_coordinates:\n",
      "                if \"type\" in has_coordinates and has_coordinates['type'] == \"Point\":\n",
      "                    coordinates__longitude = has_coordinates['coordinates'][0]\n",
      "                    coordinates__latitude = has_coordinates['coordinates'][1]\n",
      "                    are_coordinates_set = True\n",
      "                else:\n",
      "                    coordinates__longitude = None\n",
      "                    coordinates__latitude = None\n",
      "            else:\n",
      "                coordinates__longitude = None\n",
      "                coordinates__latitude = None\n",
      "            has_geo = decoded['geo'] if \"geo\" in decoded else None\n",
      "            if not are_coordinates_set:\n",
      "                if has_geo:\n",
      "                    if \"type\" in has_geo and has_geo['type'] == \"Point\":\n",
      "                        coordinates__longitude = has_geo['coordinates'][0]\n",
      "                        coordinates__latitude = has_geo['coordinates'][1]\n",
      "                    else:\n",
      "                        coordinates__longitude = None\n",
      "                        coordinates__latitude = None\n",
      "                else:\n",
      "                    coordinates__longitude = None\n",
      "                    coordinates__latitue = None\n",
      "            retweet_count = decoded['retweet_count'] if \"retweet_count\" in decoded else None\n",
      "            favorite_count = decoded['favorite_count'] if \"favorite_count\" in decoded else None\n",
      "            filter_level = decoded['filter_level'] if \"filter_level\" in decoded else None\n",
      "            timestamp_ms = decoded['timestamp_ms'] if \"timestamp_ms\" in decoded else None\n",
      "            lang = decoded['lang'] if \"lang\" in decoded else None\n",
      "            place = decoded['place'] if \"place\" in decoded else None\n",
      "            \n",
      "            user_list_insert = []\n",
      "            if \"user\" in decoded:\n",
      "                user_list = []\n",
      "                user_list.append(tweet_id)\n",
      "                user_list.append(decoded['user']['id']) if \"id\" in decoded['user'] else user_list.append(None)\n",
      "                user_list.append(decoded['user']['name']) if \"name\" in decoded['user'] else user_list.append(None)\n",
      "                user_list.append(decoded['user']['screen_name']) if \"screen_name\" in decoded['user'] else user_list.append(None)\n",
      "                user_list.append(decoded['user']['location']) if \"location\" in decoded['user'] else user_list.append(None)\n",
      "                user_list.append(decoded['user']['description']) if \"description\" in decoded['user'] else user_list.append(None)\n",
      "                user_list.append(decoded['user']['protected']) if \"protected\" in decoded['user'] else user_list.append(None)\n",
      "                user_list.append(decoded['user']['verified']) if \"verified\" in decoded['user'] else user_list.append(None)\n",
      "                user_list.append(decoded['user']['followers_count']) if \"followers_count\" in decoded['user'] else user_list.append(None)\n",
      "                user_list.append(decoded['user']['friends_count']) if \"friends_count\" in decoded['user'] else user_list.append(None)\n",
      "                user_list.append(decoded['user']['listed_count']) if \"listed_count\" in decoded['user'] else user_list.append(None)\n",
      "                user_list.append(decoded['user']['favourites_count']) if \"favourites_count\" in decoded['user'] else user_list.append(None)\n",
      "                user_list.append(decoded['user']['statuses_count']) if \"statuses_count\" in decoded['user'] else user_list.append(None)\n",
      "                user_list.append(decoded['user']['created_at']) if \"created_at\" in decoded['user'] else user_list.append(None)\n",
      "                user_list.append(decoded['user']['utc_offset']) if \"utc_offset\" in decoded['user'] else user_list.append(None)\n",
      "                user_list.append(decoded['user']['time_zone']) if \"time_zone\" in decoded['user'] else user_list.append(None)\n",
      "                user_list.append(decoded['user']['geo_enabled']) if \"geo_enabled\" in decoded['user'] else user_list.append(None)\n",
      "                user_list.append(decoded['user']['lang']) if \"lang\" in decoded['user'] else user_list.append(None)\n",
      "                user_list.append(decoded['user']['contributors_enabled']) if \"contributors_enabled\" in decoded['user'] else user_list.append(None)\n",
      "                user_list.append(decoded['user']['is_translator']) if \"is_translator\" in decoded['user'] else user_list.append(None)\n",
      "                user_list.append(decoded['user']['profile_background_color']) if \"profile_background_color\" in decoded['user'] else user_list.append(None)\n",
      "                \n",
      "                profile_background_image_url = decoded['user']['profile_background_image_url'] if \"profile_background_image_url\" in decoded['user'] else None\n",
      "                if profile_background_image_url and len(profile_background_image_url) > 1000:\n",
      "                    profile_background_image_url = \"MaxFieldLengthExceeded\"\n",
      "                user_list.append(profile_background_image_url)\n",
      "                profile_background_image_url_https = decoded['user']['profile_background_image_url_https'] if \"profile_background_image_url_https\" in decoded['user'] else None\n",
      "                if profile_background_image_url_https and len(profile_background_image_url_https) > 1000:\n",
      "                    profile_background_image_url_https = \"MaxFieldLengthExceeded\"\n",
      "                user_list.append(profile_background_image_url_https)\n",
      "                user_list.append(decoded['user']['profile_use_background_image']) if \"profile_use_background_image\" in decoded['user'] else user_list.append(None)\n",
      "                profile_image_url = decoded['user']['profile_image_url'] if \"profile_image_url\" in decoded['user'] else None\n",
      "                if profile_image_url and len(profile_image_url) > 1000:\n",
      "                    profile_image_url = \"MaxFieldLengthExceeded\"\n",
      "                user_list.append(profile_image_url)\n",
      "                profile_image_url_https = decoded['user']['profile_image_url_https'] if \"profile_image_url_https\" in decoded['user'] else None\n",
      "                if profile_image_url_https and len(profile_image_url_https) > 1000:\n",
      "                    profile_image_url_https = \"MaxFieldLengthExceeded\"\n",
      "                user_list.append(profile_image_url_https)\n",
      "                profile_banner_url = decoded['user']['profile_banner_url'] if \"profile_banner_url\" in decoded['user'] else None\n",
      "                if profile_banner_url and len(profile_banner_url) > 1000:\n",
      "                    profile_banner_url = \"MaxFieldLengthExceeded\"\n",
      "                user_list.append(profile_banner_url)\n",
      "                user_list.append(decoded['user']['default_profile']) if \"default_profile\" in decoded['user'] else user_list.append(None)\n",
      "                user_list.append(decoded['user']['default_profile_image']) if \"default_profile_image\" in decoded['user'] else user_list.append(None)     \n",
      "                user_list.append(decoded['user']['profile_sidebar_fill_color']) if \"profile_sidebar_fill_color\" in decoded['user'] else user_list.append(None)\n",
      "                user_list.append(decoded['user']['profile_sidebar_border_color']) if \"profile_sidebar_border_color\" in decoded['user'] else user_list.append(None)\n",
      "                user_list.append(decoded['user']['profile_text_color']) if \"profile_text_color\" in decoded['user'] else user_list.append(None)\n",
      "                user_list.append(decoded['user']['profile_link_color']) if \"profile_link_color\" in decoded['user'] else user_list.append(None)\n",
      "                user_list.append(decoded['user']['profile_background_title']) if \"profile_background_title\" in decoded['user'] else user_list.append(None)\n",
      "                url = decoded['user']['url'] if \"url\" in decoded['user'] else None\n",
      "                if url and len(url) > 1000:\n",
      "                    url = \"MaxFieldLengthExceeded\"\n",
      "                user_list.append(url)\n",
      "                user_list_insert.append(user_list)\n",
      "            \n",
      "            media_list_insert = []\n",
      "            if \"entities\" in decoded:\n",
      "                if \"media\" in decoded['entities']:\n",
      "                    has_entities_media = 1\n",
      "                    for media_item in decoded['entities']['media']:\n",
      "                        media_list = []\n",
      "                        media_list.append(tweet_id)\n",
      "                        media_list.append(media_item['id']) if \"id\" in media_item else media_list.append(None)\n",
      "                        media_url = media_item['media_url'] if \"media_url\" in media_item else None\n",
      "                        if media_url and len(media_url) > 1000:\n",
      "                            media_url = \"MaxFieldLengthExceeded\"\n",
      "                        media_list.append(media_url)\n",
      "                        media_url_https = media_item['media_url_https'] if \"media_url_https\" in media_item else None\n",
      "                        if media_url_https and len(media_url_https) > 1000:\n",
      "                            media_url_https = \"MaxFieldLengthExceeded\"\n",
      "                        media_list.append(media_url_https)\n",
      "                        media_url = media_item['url'] if \"url\" in media_item else None\n",
      "                        if media_url and len(media_url) > 1000:\n",
      "                            media_url = \"MaxFieldLengthExceeded\"\n",
      "                        media_list.append(media_url)\n",
      "                        display_url = media_item['display_url'] if \"display_url\" in media_item else None\n",
      "                        if display_url and len(display_url) > 1000:\n",
      "                            display_url = \"MaxFieldLengthExceeded\"\n",
      "                        media_list.append(display_url)\n",
      "                        expanded_url = media_item['expanded_url'] if \"expanded_url\" in media_item else None\n",
      "                        if expanded_url and len(expanded_url) > 1000:\n",
      "                            expanded_url = \"MaxFieldLengthExceeded\"\n",
      "                        media_list.append(expanded_url)\n",
      "                        media_list.append(media_item['type']) if \"type\" in media_item else media_list.append(None)\n",
      "                        media_list_insert.append(media_list)\n",
      "                else:\n",
      "                    has_entities_media = 0\n",
      "                \n",
      "                urls_list_insert = []\n",
      "                if \"urls\" in decoded['entities']:\n",
      "                    has_entities_urls = 1\n",
      "                    for url_item in decoded['entities']['urls']:\n",
      "                        url_list = []\n",
      "                        url_list.append(tweet_id)\n",
      "                        url = url_item['url'] if \"url\" in url_item else None\n",
      "                        if url and len(url) > 1000:\n",
      "                            url = \"MaxFieldLengthExceeded\"\n",
      "                        url_list.append(url)\n",
      "                        display_url = url_item['display_url'] if \"display_url\" in url_item else None\n",
      "                        if display_url and len(display_url) > 1000:\n",
      "                            display_url = \"MaxFieldLengthExceeded\"\n",
      "                        url_list.append(display_url)\n",
      "                        expanded_url = url_item['expanded_url'] if \"expanded_url\" in url_item else None\n",
      "                        if expanded_url and len(expanded_url) > 1000:\n",
      "                            expanded_url = \"MaxFieldLengthExceeded\"\n",
      "                        url_list.append(expanded_url)\n",
      "                        urls_list_insert.append(url_list)\n",
      "                else:\n",
      "                    has_entities_urls = 0\n",
      "                    \n",
      "                user_mentions_list_insert = []\n",
      "                if \"user_mentions\" in decoded['entities']:\n",
      "                    has_entities_user_mentions = 1\n",
      "                    for user_mentions_item in decoded['entities']['user_mentions']:\n",
      "                        user_mentions_list = []\n",
      "                        user_mentions_list.append(tweet_id)\n",
      "                        user_mentions_list.append(user_mentions_item['id']) if \"id\" in user_mentions_item else user_mentions_list.append(None)\n",
      "                        user_mentions_list.append(user_mentions_item['screen_name']) if \"screen_name\" in user_mentions_item else user_mentions_list.append(None)\n",
      "                        user_mentions_list.append(user_mentions_item['name']) if \"name\" in user_mentions_item else user_mentions_list.append(None)\n",
      "                        user_mentions_list_insert.append(user_mentions_list)\n",
      "                else:\n",
      "                    has_entities_user_mentions = 0\n",
      "                \n",
      "                hashtag_list_insert = []\n",
      "                if \"hashtags\" in decoded['entities']:\n",
      "                    has_entities_hashtags = 1\n",
      "                    for hashtag_item in decoded['entities']['hashtags']:\n",
      "                        hashtag_list = []\n",
      "                        hashtag_list.append(tweet_id)\n",
      "                        hashtag_list.append(hashtag_item['text']) if \"text\" in hashtag_item else hashtag_list.append(None)\n",
      "                        hashtag_list_insert.append(hashtag_list)\n",
      "                else:\n",
      "                    has_entities_hashtags = 0\n",
      "                \n",
      "                symbols_list_insert = []\n",
      "                if \"symbols\" in decoded['entities']:\n",
      "                    has_entities_symbols = 1\n",
      "                    for symbols_item in decoded['entities']['symbols']:\n",
      "                        symbols_list = []\n",
      "                        symbols_list.append(tweet_id)\n",
      "                        symbols_list.append(symbols_item['text']) if \"text\" in symbols_item else symbols_list.append(None)\n",
      "                        symbols_list_insert.append(symbols_list)\n",
      "                else:\n",
      "                    has_entities_symbols = 0\n",
      "                \n",
      "                extended_entities_list_insert = []\n",
      "                if \"extended_entities\" in decoded['entities']:\n",
      "                    has_entities_extended_entities = 1\n",
      "                    for extended_entities_item in decoded['entities']['extended_entities']:\n",
      "                        extended_entities_list = []\n",
      "                        extended_entities_list.append(tweet_id)\n",
      "                        extended_entities_list.append(extended_entities_item['id']) if \"id\" in extended_entities_item else extended_entities_list.append(None)\n",
      "                        media_url = extended_entities_item['media_url'] if \"media_url\" in extended_entities_item else None\n",
      "                        if media_url and len(media_url) > 1000:\n",
      "                            media_url = \"MaxFieldLengthExceeded\"\n",
      "                        extended_entities_list.append(media_url)\n",
      "                        media_url_https = extended_entities_item['media_url_https'] if \"media_url_https\" in extended_entities_item else None\n",
      "                        if media_url_https and len(media_url_https) > 1000:\n",
      "                            media_url_https = \"MaxFieldLengthExceeded\"\n",
      "                        extended_entities_list.append(media_url_https)\n",
      "                        url = extended_entities_item['url'] if \"url\" in extended_entities_item else None\n",
      "                        if url and len(url) > 1000:\n",
      "                            url = \"MaxFieldLengthExceeded\"\n",
      "                        extended_entities_list.append(url)\n",
      "                        display_url = extended_entities_item['display_url'] if \"display_url\" in extended_entities_item else None\n",
      "                        if display_url and len(display_url) > 1000:\n",
      "                            display_url = \"MaxFieldLengthExceeded\"\n",
      "                        extended_entities_list.append(display_url)\n",
      "                        expanded_url = extended_entities_item['expanded_url'] if \"expanded_url\" in extended_entities_item else None\n",
      "                        if expanded_url and len(expanded_url) > 1000:\n",
      "                            expanded_url = \"MaxFieldLengthExceeded\"\n",
      "                        extended_entities_list.append(expanded_url)\n",
      "                        extended_entities_list.append(extended_entities_item['type']) if \"type\" in extended_entities_item else extended_entities_list.append(None)\n",
      "                        extended_entities_list_insert.append(extended_entities_list)\n",
      "                else:\n",
      "                    has_entities_extended_entities = 0\n",
      "                    \n",
      "            else:\n",
      "                has_entities_media =  has_entities_urls = has_entities_user_mentions = has_entities_hashtags = None\n",
      "                has_entities_symbols = has_entities_extended_entities = None\n",
      "                media_list_insert = urls_list_insert = user_mentions_list_insert = hashtag_list_insert = []\n",
      "                symbols_list_insert = extended_entities_list_insert = []\n",
      "            \n",
      "        \n",
      "            tweet_insert_list = [tweet_id, created_at, tweet_text, tweet_source, truncated, in_reply_to_status_id, \\\n",
      "                                 in_reply_to_user_id, in_reply_to_user_screen_name, coordinates__longitude, coordinates__latitude, \\\n",
      "                                 retweet_count, favorite_count, filter_level, timestamp_ms, lang, \\\n",
      "                                 has_entities_media, has_entities_urls, has_entities_user_mentions, has_entities_hashtags, \\\n",
      "                                 has_entities_symbols, has_entities_extended_entities, self.search_string]\n",
      "            \n",
      "            try:\n",
      "                insert_Tweets = \"\"\"insert into TwitterDev.dbo.Tweets (\n",
      "                    tweet_id, created_at, tweet_text, tweet_source, truncated, in_reply_to_status_id, in_reply_to_user_id\n",
      "                    ,in_reply_to_user_screen_name, coordinates__longitude, coordinates__latitude, retweet_count, favorite_count\n",
      "                    ,filter_level, timestamp_ms, lang\n",
      "                    \n",
      "                    ,has_entities_media, has_entities_urls, has_entities_user_mentions, has_entities_hashtags\n",
      "                    ,has_entities_symbols, has_entities_extended_entities\n",
      "                    ,search_string)\n",
      "                    values (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\n",
      "                \"\"\"\n",
      "                cursor.execute(insert_Tweets, tweet_insert_list)\n",
      "                cursor.commit()\n",
      "                \n",
      "                if user_list_insert:\n",
      "                    for user_list in user_list_insert:\n",
      "                        insert_TweetUser = \"\"\"insert into TwitterDev.dbo.TweetUsers (\n",
      "                            tweet_id, [user_id], name, screen_name, location, user_description, protected, verified, \n",
      "                            followers_count, friends_count, listed_count, favourites_count, statuses_count, created_at, utc_offset, \n",
      "                            time_zone, geo_enabled, lang, contributors_enabled, is_translator, profile_background_color, \n",
      "                            profile_background_image_url, profile_background_image_url_https, profile_use_background_image,\n",
      "                            profile_image_url, profile_image_url_https, profile_banner_url, default_profile, default_profile_image, \n",
      "                            profile_sidebar_fill_color, profile_sidebar_border_color, profile_text_color, profile_link_color,\n",
      "                            profile_background_title, user_url\n",
      "                            )\n",
      "                            values (\n",
      "                            ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, \n",
      "                            ?, ?, ?, ?, ?, ?)\n",
      "                        \"\"\"\n",
      "                        cursor.execute(insert_TweetUser, user_list)\n",
      "                        cursor.commit()\n",
      "\n",
      "                if media_list_insert:\n",
      "                    for media_list in media_list_insert:\n",
      "                        insert_TweetEntitiesMedia = \"\"\"insert into TwitterDev.dbo.TweetEntitiesMedia (\n",
      "                            tweet_id, media_id, media_url, media_url_https, url, display_url, expanded_url, media_type)\n",
      "                            values (\n",
      "                            ?, ?, ?, ?, ?, ?, ?, ?)\n",
      "                        \"\"\"\n",
      "                        cursor.execute(insert_TweetEntitiesMedia, media_list)\n",
      "                        cursor.commit()\n",
      "                \n",
      "                if urls_list_insert:\n",
      "                    for url_list in urls_list_insert:\n",
      "                        insert_TweetEntitiesURLs = \"\"\"insert into TwitterDev.dbo.TweetEntitiesURLs (\n",
      "                            tweet_id, url, display_url, expanded_url)\n",
      "                            values (?, ?, ?, ?)\n",
      "                        \"\"\"\n",
      "                        cursor.execute(insert_TweetEntitiesURLs, url_list)\n",
      "                        cursor.commit()\n",
      "                \n",
      "                if user_mentions_list_insert:\n",
      "                    for user_mentions_list in user_mentions_list_insert:\n",
      "                        insert_TweetEntitiesUserMentions = \"\"\"insert into TwitterDev.dbo.TweetEntitiesUserMentions (\n",
      "                            tweet_id, user_mention_id, screen_name, name)\n",
      "                            values (?, ?, ?, ?)\n",
      "                        \"\"\"\n",
      "                        cursor.execute(insert_TweetEntitiesUserMentions, user_mentions_list)\n",
      "                        cursor.commit()\n",
      "                        \n",
      "                if hashtag_list_insert:\n",
      "                    for hashtag_list in hashtag_list_insert:\n",
      "                        insert_TweetEntitiesHashtags = \"\"\"insert into TwitterDev.dbo.TweetEntitiesHashtags (\n",
      "                            tweet_id, hashtag_text)\n",
      "                            values (?, ?)\n",
      "                        \"\"\"\n",
      "                        cursor.execute(insert_TweetEntitiesHashtags, hashtag_list)\n",
      "                        cursor.commit()\n",
      "                \n",
      "                if symbols_list_insert:\n",
      "                    for symbols_list in symbols_list_insert:\n",
      "                        insert_TweetEntitiesSymbols = \"\"\"insert into TwitterDev.dbo.TweetEntitiesSymbols (\n",
      "                            tweet_id, symbol_text)\n",
      "                            values (?, ?)\n",
      "                        \"\"\"\n",
      "                        cursor.execute(insert_TweetEntitiesSymbols, symbols_list)\n",
      "                        cursor.commit()\n",
      "                \n",
      "                if extended_entities_list_insert:\n",
      "                    for extended_entities_list in extended_entities_list_insert:\n",
      "                        insert_TweetEntitiesExtendedEntities = \"\"\"insert into TwitterDev.dbo.TweetEntitiesExtendedEntities (\n",
      "                            tweet_id, extended_entity_id, media_url, media_url_https, url, display_url, expanded_url\n",
      "                            ,extended_entity_type)\n",
      "                            values (?, ?, ?, ?, ?, ?, ?, ?)\n",
      "                        \"\"\"\n",
      "                        cursor.execute(insert_TweetEntitiesExtendedEntities, extended_entities_list)\n",
      "                        cursor.commit()\n",
      "                \n",
      "                #cursor.commit()\n",
      "                \n",
      "            except pyodbc.ProgrammingError, err:\n",
      "                print \"Error: \" + str(err)\n",
      "            \n",
      "\n",
      "\n",
      "# This is a basic listener that just prints received tweets to stdout\n",
      "class StdOutListener(StreamListener):\n",
      "    \n",
      "    cursor = None\n",
      "    openfile = None\n",
      "    \n",
      "    def set_cursor(self, cursor):\n",
      "        self.cursor = cursor\n",
      "        \n",
      "    def set_log_file(self, filename):\n",
      "        self.openfile = filename\n",
      "    \n",
      "    def on_data(self, data):\n",
      "        \n",
      "        decoded = json.loads(data)\n",
      "        #decoded = data\n",
      "        #print type(json.loads(data))\n",
      "        \n",
      "        # Try to print the JSON out to a file\n",
      "        if self.openfile:\n",
      "            self.openfile.write(json.dumps(decoded))\n",
      "            self.openfile.write(\"\\n\\n\")\n",
      "            \n",
      "        \n",
      "        # Declare SQL Connection\n",
      "        # Right now we close and open the connection a lot.\n",
      "        if self.cursor:\n",
      "            try:\n",
      "                tp.fetch_tweets(decoded, self.cursor)\n",
      "\n",
      "            except pyodbc.ProgrammingError, err:\n",
      "                print \"Error: \" + str(err)\n",
      "        \n",
      "        \n",
      "if __name__ == '__main__':\n",
      "    \n",
      "    # This handles Twitter authentification and the connection to Twitter Streaming API\n",
      "    l = StdOutListener()\n",
      "    auth = OAuthHandler(consumer_key, consumer_secret)\n",
      "    auth.set_access_token(access_token, access_token_secret)\n",
      "    \n",
      "    # Declare SQL Connection\n",
      "    tp = TweetParserDB()\n",
      "    try:\n",
      "        conn = pyodbc.connect(r'Driver={SQL Server};Server=WEIBULL;Database=master;Trusted_Connection=yes;')\n",
      "        cur = conn.cursor()\n",
      "        l.set_cursor(cur)\n",
      "    \n",
      "        try:\n",
      "            filename = \"E:\\\\Users\\\\bilquist\\\\Documents\\\\Projects\\\\TwitterScraper\\\\TweetLog\\\\TweetLogFancyCat.txt\"\n",
      "            f = open(filename,'a')\n",
      "            l.set_log_file(f)\n",
      "        except IOError, err:\n",
      "            print 'IOError: ' + str(err)\n",
      "            \n",
      "    \n",
      "        stream = Stream(auth, l)\n",
      "    \n",
      "        tp.search_string = 'crocodile'\n",
      "        # This line filters Twitter Streams to capture data by the keywords\n",
      "        stream.filter(track=[\"in a while crocodile\", \"after a while crocodile\", \"in awhile crocodile\", \"after awhile crocodile\",\n",
      "                             \"in a while, crocodile\", \"after a while, crocodile\", \"in awhile, crocodile\", \"after awhile, crocodile\"])\n",
      "        #stream.filter(track=[\"cat\", \"whale\"], stall_warnings = True)\n",
      "\n",
      "        conn.close()\n",
      "        f.close()\n",
      "        \n",
      "    except pyodbc.ProgrammingError, err:\n",
      "        print \"Error: \" + str(err)\n",
      "        conn.close()\n",
      "        f.close()\n",
      "        \n",
      "        "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#If the script failes run these so the file connections close\n",
      "conn.close()\n",
      "f.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 45
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}